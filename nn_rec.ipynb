{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2774da1b-926c-47b9-880e-a986414cfb29",
   "metadata": {},
   "source": [
    "# Neural Network Recommendation Systems"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af4ec1c2-1bfd-4a35-9fa2-6986cb9ef726",
   "metadata": {},
   "source": [
    "In this part of the project we will fit NeuralMF, AutoRec, and MF-Bayesian Popularity Ranking on the movielens 20 million dataset. We obtained 0.81 Test RMSE in NeuralMF and 0.61 in AutoRec, both performed way better than 0.95 RMSE obtained in item-item collaborative filtering. But all of these methods are for scores only, due to this we also made a baysian popularity based MF which obtained a result of Recall@10 of 0.16 which was 70-80% better than normal popularity based metric we tested and this could improve a lot as we tested a basic retriever.\n",
    "\n",
    "We can also stack the models, creating a retriever and scoring based model seperately powered by ANN, FAISS, or other vector stores and create production ready Recommendation Systems.\n",
    "\n",
    "This notebook has following parts:\n",
    "1. NeuralMF\n",
    "2. AutoRec\n",
    "3. MF-BPR\n",
    "4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6007db-a1af-4dfc-b736-732b7720bf71",
   "metadata": {},
   "source": [
    "## NeuralMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389718b2-253f-40b7-bc9e-7f47e2fcb8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 16:23:21.736728: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-06 16:23:21.783355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-06 16:23:22.514396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/anubh/miniconda3/envs/dl-env/lib/python3.11/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py:37: UserWarning: A NumPy version >=1.25.2 and <2.6.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce1a8745-e8f7-4aa7-b164-ede404ac383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pd.read_csv(\"rating.csv\")\n",
    "df_movies = pd.read_csv(\"movie.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f753d9e2-f5df-470c-9e70-16f370e9b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = pd.to_datetime(df_rating['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba1ae1f-a3db-4e66-8f7f-f8ef832fc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating['year'] = time_stamp.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ebffb0-3e23-4109-89b9-9b7cf7a45869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1612609</td>\n",
       "      <td>1612609</td>\n",
       "      <td>1612609</td>\n",
       "      <td>1612609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>700982</td>\n",
       "      <td>700982</td>\n",
       "      <td>700982</td>\n",
       "      <td>700982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>308070</td>\n",
       "      <td>308070</td>\n",
       "      <td>308070</td>\n",
       "      <td>308070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1198384</td>\n",
       "      <td>1198384</td>\n",
       "      <td>1198384</td>\n",
       "      <td>1198384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>1953659</td>\n",
       "      <td>1953659</td>\n",
       "      <td>1953659</td>\n",
       "      <td>1953659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>1186125</td>\n",
       "      <td>1186125</td>\n",
       "      <td>1186125</td>\n",
       "      <td>1186125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>869719</td>\n",
       "      <td>869719</td>\n",
       "      <td>869719</td>\n",
       "      <td>869719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>1035878</td>\n",
       "      <td>1035878</td>\n",
       "      <td>1035878</td>\n",
       "      <td>1035878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>1170049</td>\n",
       "      <td>1170049</td>\n",
       "      <td>1170049</td>\n",
       "      <td>1170049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>1803158</td>\n",
       "      <td>1803158</td>\n",
       "      <td>1803158</td>\n",
       "      <td>1803158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>1171836</td>\n",
       "      <td>1171836</td>\n",
       "      <td>1171836</td>\n",
       "      <td>1171836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>1053430</td>\n",
       "      <td>1053430</td>\n",
       "      <td>1053430</td>\n",
       "      <td>1053430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1158777</td>\n",
       "      <td>1158777</td>\n",
       "      <td>1158777</td>\n",
       "      <td>1158777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>930036</td>\n",
       "      <td>930036</td>\n",
       "      <td>930036</td>\n",
       "      <td>930036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>903691</td>\n",
       "      <td>903691</td>\n",
       "      <td>903691</td>\n",
       "      <td>903691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>766366</td>\n",
       "      <td>766366</td>\n",
       "      <td>766366</td>\n",
       "      <td>766366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>731389</td>\n",
       "      <td>731389</td>\n",
       "      <td>731389</td>\n",
       "      <td>731389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>599327</td>\n",
       "      <td>599327</td>\n",
       "      <td>599327</td>\n",
       "      <td>599327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>562888</td>\n",
       "      <td>562888</td>\n",
       "      <td>562888</td>\n",
       "      <td>562888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>283886</td>\n",
       "      <td>283886</td>\n",
       "      <td>283886</td>\n",
       "      <td>283886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId   rating  timestamp\n",
       "year                                      \n",
       "1995        4        4        4          4\n",
       "1996  1612609  1612609  1612609    1612609\n",
       "1997   700982   700982   700982     700982\n",
       "1998   308070   308070   308070     308070\n",
       "1999  1198384  1198384  1198384    1198384\n",
       "2000  1953659  1953659  1953659    1953659\n",
       "2001  1186125  1186125  1186125    1186125\n",
       "2002   869719   869719   869719     869719\n",
       "2003  1035878  1035878  1035878    1035878\n",
       "2004  1170049  1170049  1170049    1170049\n",
       "2005  1803158  1803158  1803158    1803158\n",
       "2006  1171836  1171836  1171836    1171836\n",
       "2007  1053430  1053430  1053430    1053430\n",
       "2008  1158777  1158777  1158777    1158777\n",
       "2009   930036   930036   930036     930036\n",
       "2010   903691   903691   903691     903691\n",
       "2011   766366   766366   766366     766366\n",
       "2012   731389   731389   731389     731389\n",
       "2013   599327   599327   599327     599327\n",
       "2014   562888   562888   562888     562888\n",
       "2015   283886   283886   283886     283886"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating.groupby('year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d391432d-135d-44a4-aad0-a0a9545e3bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users: 138493 n_items: 26744\n"
     ]
    }
   ],
   "source": [
    "# Dense 0..n_users-1 for all users in ratings\n",
    "user_codes, user_uniqs = pd.factorize(df_rating[\"userId\"], sort=True)\n",
    "# Dense 0..n_items-1 for all items in ratings\n",
    "item_codes, item_uniqs = pd.factorize(df_rating[\"movieId\"], sort=True)\n",
    "\n",
    "df = df_rating.copy()\n",
    "df[\"user_idx\"]  = user_codes.astype(np.int32)\n",
    "df[\"movie_idx\"] = item_codes.astype(np.int32)\n",
    "\n",
    "n_users = int(user_codes.max()) + 1\n",
    "n_items = int(item_codes.max()) + 1\n",
    "print(\"n_users:\", n_users, \"n_items:\", n_items)\n",
    "# Sanity: dense\n",
    "assert df[\"movie_idx\"].nunique() == n_items\n",
    "assert df[\"movie_idx\"].min() == 0 and df[\"movie_idx\"].max() == n_items - 1\n",
    "\n",
    "\n",
    "movieId_by_index = np.asarray(item_uniqs) \n",
    "\n",
    "movies_map = df_movies.set_index(\"movieId\")[\"title\"] if \"title\" in df_movies else pd.Series(dtype=object)\n",
    "title_by_index = (\n",
    "    pd.Series(index=movieId_by_index, data=movies_map.reindex(movieId_by_index).values)\n",
    "    .fillna(pd.Series([f\"Item #{i}\" for i in range(n_items)], index=movieId_by_index))\n",
    "    .to_numpy()\n",
    ")\n",
    "assert len(movieId_by_index) == n_items\n",
    "assert len(title_by_index)   == n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ce4aa47b-de5c-43da-bd54-b2f0e96aa789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Seen items from TRAIN only\n",
    "seen_by_user = defaultdict(set)\n",
    "for u, i in zip(train_df[\"user_idx\"].values, train_df[\"movie_idx\"].values):\n",
    "    seen_by_user[int(u)].add(int(i))\n",
    "    \n",
    "REL_THRESH = 3.8\n",
    "gt_by_user = defaultdict(set)\n",
    "for u, i, r in zip(test_df[\"user_idx\"].values, test_df[\"movie_idx\"].values, test_df[\"rating\"].values):\n",
    "    if r >= REL_THRESH:\n",
    "        gt_by_user[int(u)].add(int(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe2c1d-20ea-424e-a95e-cbd7190d6266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cec10e1a-fa0c-4887-88d2-a8e36e35ec5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      2,      3, ..., 131258, 131260, 131262],\n",
       "      shape=(27278,))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.movieId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebdf0e30-dc8b-4d34-861d-0f17f23206d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f618b7d-67a6-42d8-8f25-288e0ec82047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rating.merge(df_movies, on = 'movieId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52218e20-103a-446a-84ea-160393edbd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_idx'] = df['userId'].map(user_dict)\n",
    "df['movie_idx'] = df['movieId'].map(movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6fe68ac-a492-448d-94d8-f28a04a45691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>movie_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "      <td>2005</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "      <td>2005</td>\n",
       "      <td>City of Lost Children, The (Cité des enfants p...</td>\n",
       "      <td>Adventure|Drama|Fantasy|Mystery|Sci-Fi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "      <td>2005</td>\n",
       "      <td>Twelve Monkeys (a.k.a. 12 Monkeys) (1995)</td>\n",
       "      <td>Mystery|Sci-Fi|Thriller</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "      <td>2005</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "      <td>2005</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp  year  \\\n",
       "0       1        2     3.5  2005-04-02 23:53:47  2005   \n",
       "1       1       29     3.5  2005-04-02 23:31:16  2005   \n",
       "2       1       32     3.5  2005-04-02 23:33:39  2005   \n",
       "3       1       47     3.5  2005-04-02 23:32:07  2005   \n",
       "4       1       50     3.5  2005-04-02 23:29:40  2005   \n",
       "\n",
       "                                               title  \\\n",
       "0                                     Jumanji (1995)   \n",
       "1  City of Lost Children, The (Cité des enfants p...   \n",
       "2          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
       "3                        Seven (a.k.a. Se7en) (1995)   \n",
       "4                         Usual Suspects, The (1995)   \n",
       "\n",
       "                                   genres  user_idx  movie_idx  \n",
       "0              Adventure|Children|Fantasy         0          0  \n",
       "1  Adventure|Drama|Fantasy|Mystery|Sci-Fi         0          1  \n",
       "2                 Mystery|Sci-Fi|Thriller         0          2  \n",
       "3                        Mystery|Thriller         0          3  \n",
       "4                  Crime|Mystery|Thriller         0          4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fee81b7b-c905-4312-b6dc-9b23ad07ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporal based split if needed, it didn't work so well in our case\n",
    "# def temporal_split_per_user(df, val_frac=0.1, test_frac=0.1, min_train=1):\n",
    "#     # df must include: user_idx, item_idx, rating, timestamp\n",
    "#     parts = []\n",
    "#     for u, g in df.groupby(\"user_idx\", sort=False):\n",
    "#         g = g.sort_values(\"timestamp\")\n",
    "#         n = len(g)\n",
    "#         n_test = int(n * test_frac)\n",
    "#         n_val  = int(n * val_frac)\n",
    "#         n_train = n - n_val - n_test\n",
    "#         if n_train < min_train:\n",
    "#             # Not enough history → put all into train (or skip user)\n",
    "#             parts.append((g, g.iloc[0:0], g.iloc[0:0]))\n",
    "#             continue\n",
    "#         g_train = g.iloc[: n_train]\n",
    "#         g_val   = g.iloc[n_train: n_train + n_val]\n",
    "#         g_test  = g.iloc[n_train + n_val:]\n",
    "#         parts.append((g_train, g_val, g_test))\n",
    "#     train = pd.concat([p[0] for p in parts], ignore_index=True)\n",
    "#     val   = pd.concat([p[1] for p in parts], ignore_index=True)\n",
    "#     test  = pd.concat([p[2] for p in parts], ignore_index=True)\n",
    "#     return train, val, test\n",
    "\n",
    "# train_df, val_df, test_df = temporal_split_per_user(df, val_frac=0.1, test_frac=0.1, min_train=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c5dca2-4723-4208-b3d1-4de73cd6fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c95f5a7-1e85-4d85-bf6d-0cc9b64aba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size = 0.1, random_state= 10)\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.1, random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6700154-208b-4cce-bee9-9bf576c8d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759682619.334783  872161 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5561 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "def process_df(df):\n",
    "    x = {'user_idx': df['user_idx'].astype(np.int32).values, 'movie_idx': df['movie_idx'].astype(np.int32).values}\n",
    "    y = df['rating'].astype(np.float32).values\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y)).batch(32000).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = process_df(train_df)\n",
    "val_ds = process_df(val_df)\n",
    "test_ds = process_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68747b-6e48-44d7-9b47-1c3bc7a4f032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025190c3-07e5-4472-b160-23f6347866e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #removing movies which never appeared in training dataset\n",
    "# val_df = val_df[val_df['movie_idx'].isin(set(train_df[\"movie_idx\"].unique()))].copy()\n",
    "# test_df = test_df[test_df['movie_idx'].isin(set(train_df[\"movie_idx\"].unique()))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "30e1770d-885a-4980-b0c7-bb22e2d64191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138491"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['userId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5279e835-9bde-4c8f-a37d-b77a0b459bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(df['userId'].unique())\n",
    "n_movies = len(df['movieId'].unique())\n",
    "\n",
    "class MFModel(Model):\n",
    "    def __init__(self, n_users, n_movies, dims = 128, l2 = 0.0001, init_mu = 3.52):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_emb = layers.Embedding(n_users, dims, embeddings_regularizer = regularizers.l2(l2))\n",
    "        self.movie_emb = layers.Embedding(n_movies, dims, embeddings_regularizer = regularizers.l2(l2))\n",
    "        \n",
    "        self.user_bias = layers.Embedding(n_users, 1, embeddings_regularizer = regularizers.l2(l2))\n",
    "        self.movie_bias = layers.Embedding(n_movies, 1, embeddings_regularizer = regularizers.l2(l2))\n",
    "\n",
    "        self.global_mu = tf.Variable([init_mu], dtype = tf.float32, trainable = True)\n",
    "\n",
    "        #NN part\n",
    "        \n",
    "        self.res1 = layers.Dense(64, use_bias= False)\n",
    "        self.dense1a = layers.Dense(64, activation= 'relu')\n",
    "        self.drop1 = layers.Dropout(0.2)\n",
    "        self.dense1b = layers.Dense(64, activation= 'relu')\n",
    "\n",
    "        self.res2 = layers.Add()\n",
    "        self.dense2a = layers.Dense(dims, activation= 'relu')\n",
    "        self.drop2 = layers.Dropout(0.2)\n",
    "        self.dense2b = layers.Dense(dims, activation= 'relu')\n",
    "\n",
    "        self.res3 = layers.Add()\n",
    "        self.dense3a = layers.Dense(dims, activation= 'relu')\n",
    "        self.drop3 = layers.Dropout(0.2)\n",
    "        self.dense3b = layers.Dense(dims, activation= 'relu')\n",
    "        \n",
    "        self.out = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        u = inputs['user_idx']\n",
    "        m = inputs['movie_idx']\n",
    "        gu = self.user_emb(u)\n",
    "        gm = self.movie_emb(m)\n",
    "\n",
    "        g_out = gu*gm\n",
    "\n",
    "        dn_u = self.user_emb(u)\n",
    "        dn_m = self.movie_emb(m)\n",
    "        x = tf.concat([dn_u, dn_m], axis = 1)\n",
    "\n",
    "\n",
    "        #block 1\n",
    "        x_res = self.res1(x)\n",
    "        x = self.dense1a(x_res)\n",
    "        x = self.drop1(x)\n",
    "        x = self.dense1b(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        #block 2\n",
    "        x = self.res2([x, x_res])\n",
    "        x = self.dense2a(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.dense2b(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "\n",
    "        #block 3\n",
    "        x = self.res3([x, g_out])\n",
    "        x = self.dense3a(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.dense3b(x)\n",
    "        x = self.drop3(x)\n",
    "        \n",
    "        x = tf.concat([g_out, x], axis = 1)\n",
    "        y = tf.squeeze(self.out(x), -1)\n",
    "        \n",
    "        bu = tf.squeeze(self.user_bias(u), axis = -1)\n",
    "        bm = tf.squeeze(self.movie_bias(m), axis = -1)\n",
    "\n",
    "        \n",
    "\n",
    "        pred = self.global_mu + bu + bm + y\n",
    "\n",
    "        return pred                                       \n",
    "                                          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e22f972a-23bf-4c1d-99d3-ec1475bc117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempm1 = MFModel(n_users, n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce5b3f1c-12fd-4ab2-99dd-c9f0f3226513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mf_model_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mf_model_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │    <span style=\"color: #00af00; text-decoration-color: #00af00\">17,727,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,423,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">138,493</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │    \u001b[38;5;34m17,727,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │     \u001b[38;5;34m3,423,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │       \u001b[38;5;34m138,493\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_11 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │        \u001b[38;5;34m26,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │        \u001b[38;5;34m16,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,398,390</span> (81.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,398,390\u001b[0m (81.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,398,390</span> (81.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,398,390\u001b[0m (81.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = tempm1({\"user_idx\": tf.zeros([1], tf.int32),\n",
    "           \"movie_idx\": tf.zeros([1], tf.int32)})\n",
    "tempm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bf72b0a-2472-420a-9f55-5e3ee8da1658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_idx': <tf.Tensor: shape=(32000,), dtype=int32, numpy=\n",
      "array([ 22883,   3655,   3617, ...,  63193, 110865,  47909],\n",
      "      shape=(32000,), dtype=int32)>, 'movie_idx': <tf.Tensor: shape=(32000,), dtype=int32, numpy=\n",
      "array([  651,   533, 10759, ...,  2626,  2093,   688],\n",
      "      shape=(32000,), dtype=int32)>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 14:32:14.779263: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for i, j in train_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55547b36-1f20-44ad-8851-e9304ec1e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, 0.5, 5.0)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9eb4eee-42bd-4ccc-ab84-79a411bcdbd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 99ms/step - loss: 0.7368 - rmse: 0.8576 - val_loss: 0.6886 - val_rmse: 0.8296 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 79ms/step - loss: 0.6596 - rmse: 0.8120 - val_loss: 0.6645 - val_rmse: 0.8150 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 75ms/step - loss: 0.6016 - rmse: 0.7754 - val_loss: 0.6758 - val_rmse: 0.8218 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 74ms/step - loss: 0.5588 - rmse: 0.7473 - val_loss: 0.7004 - val_rmse: 0.8360 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 71ms/step - loss: 0.5276 - rmse: 0.7260 - val_loss: 0.6789 - val_rmse: 0.8237 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - loss: 0.5073 - rmse: 0.7118 - val_loss: 0.6880 - val_rmse: 0.8290 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - loss: 0.4832 - rmse: 0.6946 - val_loss: 0.6820 - val_rmse: 0.8255 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "l2 = 0.0\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "\n",
    "model = MFModel(n_users, n_movies, dims = 256, l2 = l2)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"mse\",\n",
    "    metrics=[rmse]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_rmse\", patience=5, restore_best_weights=True, mode = 'min'\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor= 'val_loss', factor= 0.5, patience = 2)]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1120d-cd73-47a2-af8c-a2af4b39408d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41b703d0-115d-4818-bf07-73fb6391e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.6641 - rmse: 0.8149\n",
      "Test metrics: {'loss': 0.6641114354133606, 'rmse': 0.8148663640022278}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = model.evaluate(test_ds, return_dict=True)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "acd48e2c-d36c-4874-949e-2402206177ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>user_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000258</th>\n",
       "      <td>138493</td>\n",
       "      <td>138492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000259</th>\n",
       "      <td>138493</td>\n",
       "      <td>138492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000260</th>\n",
       "      <td>138493</td>\n",
       "      <td>138492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000261</th>\n",
       "      <td>138493</td>\n",
       "      <td>138492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000262</th>\n",
       "      <td>138493</td>\n",
       "      <td>138492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  user_idx\n",
       "0              1         0\n",
       "1              1         0\n",
       "2              1         0\n",
       "3              1         0\n",
       "4              1         0\n",
       "...          ...       ...\n",
       "20000258  138493    138492\n",
       "20000259  138493    138492\n",
       "20000260  138493    138492\n",
       "20000261  138493    138492\n",
       "20000262  138493    138492\n",
       "\n",
       "[20000263 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"userId\",\"user_idx\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9113b4b2-45cd-46e3-8d4c-843da616cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user(raw_user_id, topN=10, batch=200000):\n",
    "    # Map raw userId -> user_idx\n",
    "    row = df[[\"userId\", \"user_idx\"]].drop_duplicates()\n",
    "    row = row[row[\"userId\"] == raw_user_id]\n",
    "    if row.empty:\n",
    "        return []  # cold-start user: handle elsewhere\n",
    "\n",
    "    uidx = int(row[\"user_idx\"].iloc[0])\n",
    "\n",
    "    n_items = int(model.movie_emb.input_dim)\n",
    "    \n",
    "    # Score all items for this user in batches\n",
    "    scores = np.empty(n_items, dtype=np.float32)\n",
    "    for start in range(0, n_items, batch):\n",
    "        end = min(start + batch, n_items)\n",
    "        # Ensure int32 for embedding inputs\n",
    "        u_batch = tf.fill([end - start], tf.cast(uidx, tf.int32))\n",
    "        i_batch = tf.range(start, end, dtype=tf.int32)\n",
    "\n",
    "        s = model({\"user_idx\": u_batch, \"movie_idx\": i_batch}, training=False).numpy()\n",
    "        scores[start:end] = s\n",
    "\n",
    "    # Mask already seen items\n",
    "    seen = list(seen_by_user.get(uidx, []))\n",
    "    # Keep only valid indices\n",
    "    seen = [i for i in seen if 0 <= i < n_items]\n",
    "    if seen:\n",
    "        scores[seen] = -1e9\n",
    "\n",
    "    # Top-N extraction\n",
    "    top_idx = np.argpartition(scores, -topN)[-topN:]\n",
    "    top_idx = top_idx[np.argsort(scores[top_idx])[::-1]]\n",
    "\n",
    "    rec_movieIds = movieId_by_index[top_idx].tolist()\n",
    "    rec_titles   = title_by_index[top_idx].tolist()\n",
    "\n",
    "    return list(zip(rec_movieIds, rec_titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "831c88a0-a1ae-4e3b-a043-080a5eb1019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(858, 'Godfather, The (1972)'),\n",
       " (318, 'Shawshank Redemption, The (1994)'),\n",
       " (7502, 'Band of Brothers (2001)'),\n",
       " (93040, 'Civil War, The (1990)'),\n",
       " (527, \"Schindler's List (1993)\"),\n",
       " (912, 'Casablanca (1942)'),\n",
       " (77658, 'Cosmos (1980)'),\n",
       " (50, 'Usual Suspects, The (1995)'),\n",
       " (82143, 'Alone in the Wilderness (2004)'),\n",
       " (1148, 'Wallace & Gromit: The Wrong Trousers (1993)')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_for_user(502, topN = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9687773-03c4-4ab7-a4d1-446753a5f418",
   "metadata": {},
   "source": [
    "## AutoRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9698353-d1fb-47f1-9e0c-a31e0127f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "n_users = int(df[\"user_idx\"].max()) + 1\n",
    "n_items = int(df[\"movie_idx\"].max()) + 1\n",
    "global_mean = df['rating'].mean()\n",
    "\n",
    "def build_csr(dataframe, n_users, n_items):\n",
    "    rows = dataframe[\"user_idx\"].to_numpy(np.int32)\n",
    "    cols = dataframe[\"movie_idx\"].to_numpy(np.int32)\n",
    "    vals = dataframe[\"rating\"].to_numpy(np.float32)\n",
    "    return sp.csr_matrix((vals, (rows, cols)), shape=(n_users, n_items))\n",
    "\n",
    "train_csr = build_csr(train_df, n_users, n_items)\n",
    "val_csr   = build_csr(val_df,   n_users, n_items)\n",
    "test_csr  = build_csr(test_df,  n_users, n_items)\n",
    "\n",
    "def make_user_autorec_ds(csr_mat, n_items, batch_size=512, shuffle=True):\n",
    "    user_ids = np.arange(csr_mat.shape[0], dtype=np.int32)\n",
    "\n",
    "    def gen():\n",
    "        idx = user_ids.copy()\n",
    "        if shuffle:\n",
    "            np.random.shuffle(idx)\n",
    "        for u in idx:\n",
    "            row = csr_mat.getrow(u).toarray().astype(np.float32).squeeze(0) \n",
    "            yield row, row #(x,y)\n",
    "\n",
    "    spec = (\n",
    "        tf.TensorSpec(shape=(n_items,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(n_items,), dtype=tf.float32),\n",
    "    )\n",
    "    ds = tf.data.Dataset.from_generator(gen, output_signature=spec)\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def center_csr_global(csr, mean):\n",
    "    # Returns a new CSR with values shifted by -mean, adding this here seperately, can be commented to remove if dont want centered\n",
    "    return sp.csr_matrix((csr.data - mean, csr.indices, csr.indptr), shape=csr.shape)\n",
    "\n",
    "train_csr = center_csr_global(train_csr, global_mean)\n",
    "val_csr   = center_csr_global(val_csr,   global_mean)\n",
    "test_csr  = center_csr_global(test_csr,  global_mean)\n",
    "\n",
    "\n",
    "train_ds = make_user_autorec_ds(train_csr, n_items, 512, True)\n",
    "val_ds   = make_user_autorec_ds(val_csr,   n_items, 512, False)\n",
    "test_ds  = make_user_autorec_ds(test_csr,  n_items, 512, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f385c845-e54d-4c0c-bcdb-78b4e583dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(n_items,), dtype=tf.float32)\n",
    "\n",
    "x = layers.Dropout(0.6)(inputs)  \n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "out = layers.Dense(n_items, activation=None)(x)\n",
    "model_auto = tf.keras.Model(inputs, out)\n",
    "\n",
    "def masked_mse(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0.0), tf.float32)\n",
    "    diff2 = tf.square(y_pred - y_true) * mask\n",
    "    return tf.reduce_sum(diff2) / (tf.reduce_sum(mask) + 1e-8)\n",
    "\n",
    "class MaskedRMSE(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.se = self.add_weight(name=\"se\", shape=(), initializer=\"zeros\", dtype=tf.float32)\n",
    "        self.w  = self.add_weight(name=\"w\",  shape=(), initializer=\"zeros\", dtype=tf.float32)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        mask = tf.cast(tf.not_equal(y_true, 0.0), tf.float32)\n",
    "        diff2 = tf.square(y_pred - y_true) * mask\n",
    "        self.se.assign_add(tf.reduce_sum(diff2))\n",
    "        self.w.assign_add(tf.reduce_sum(mask))\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.se / (self.w + 1e-8))\n",
    "    def reset_states(self):\n",
    "        self.se.assign(0.0); self.w.assign(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f31bf6a1-d456-467f-af84-cc07efeaea2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26717</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26717</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,679,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26717</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,446,493</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26717\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26717\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m13,679,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26717\u001b[0m)          │     \u001b[38;5;34m3,446,493\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,290,333</span> (65.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,290,333\u001b[0m (65.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,290,333</span> (65.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,290,333\u001b[0m (65.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_auto.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6223f339-8bc8-4cfa-b573-3e7f9722083a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:29:17.079346: I external/local_xla/xla/service/service.cc:163] XLA service 0x55bcf6f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-05 23:29:17.079586: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-10-05 23:29:17.158462: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-05 23:29:17.461260: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 90501\n",
      "2025-10-05 23:29:18.449544: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_507', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "2025-10-05 23:29:18.932904: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_635', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-10-05 23:29:19.346462: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_507', 1428 bytes spill stores, 1488 bytes spill loads\n",
      "\n",
      "2025-10-05 23:29:19.365395: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_629', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2025-10-05 23:29:19.526122: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_635', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n",
      "2025-10-05 23:29:19.632853: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_631', 1100 bytes spill stores, 1100 bytes spill loads\n",
      "\n",
      "2025-10-05 23:29:19.851360: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_635', 984 bytes spill stores, 984 bytes spill loads\n",
      "\n",
      "2025-10-05 23:29:19.953589: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_593', 460 bytes spill stores, 456 bytes spill loads\n",
      "\n",
      "2025-10-05 23:29:19.964022: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_629', 376 bytes spill stores, 376 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown \u001b[1m6s\u001b[0m 6s/step - loss: 1.1709 - rmse: 1.0821"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759687161.607921  872458 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    270/Unknown \u001b[1m60s\u001b[0m 203ms/step - loss: 0.9161 - rmse: 0.9561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:30:17.324649: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_528', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-10-05 23:30:17.333614: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_514', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "2025-10-05 23:30:17.442405: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_629', 92 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-10-05 23:30:17.512183: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_635', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-10-05 23:30:17.659456: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_593', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2025-10-05 23:30:17.844036: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_507', 1672 bytes spill stores, 1700 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    271/Unknown \u001b[1m64s\u001b[0m 214ms/step - loss: 0.9157 - rmse: 0.9559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:30:19.339113: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-10-05 23:30:19.339176: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-10-05 23:30:19.339187: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:30:19.339273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n",
      "/home/anubh/miniconda3/envs/dl-env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 418ms/step - loss: 0.8262 - rmse: 0.9088 - val_loss: 0.6002 - val_rmse: 0.7752 - learning_rate: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:31:14.304405: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-10-05 23:31:14.304541: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:31:14.304572: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.6782 - rmse: 0.8235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:32:10.800543: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:32:10.800607: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 404ms/step - loss: 0.6682 - rmse: 0.8176 - val_loss: 0.4533 - val_rmse: 0.6738 - learning_rate: 0.0010\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:33:04.037144: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-10-05 23:33:04.037197: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:33:04.037225: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 394ms/step - loss: 0.6091 - rmse: 0.7804 - val_loss: 0.4204 - val_rmse: 0.6489 - learning_rate: 0.0010\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:34:50.922964: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:34:50.923060: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.5643 - rmse: 0.7512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:35:46.555357: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:35:46.555453: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 402ms/step - loss: 0.5670 - rmse: 0.7529 - val_loss: 0.4079 - val_rmse: 0.6392 - learning_rate: 0.0010\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:36:40.027279: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-10-05 23:36:40.027337: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:36:40.027364: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.5365 - rmse: 0.7323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:37:34.885632: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:37:34.885735: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 400ms/step - loss: 0.5402 - rmse: 0.7349 - val_loss: 0.3867 - val_rmse: 0.6223 - learning_rate: 0.0010\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:38:28.258460: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:38:28.258537: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.5170 - rmse: 0.7191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:39:25.284009: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:39:25.284114: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 413ms/step - loss: 0.5248 - rmse: 0.7247 - val_loss: 0.3886 - val_rmse: 0.6238 - learning_rate: 0.0010\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:40:20.328264: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:40:20.328361: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.5052 - rmse: 0.7110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:41:16.139341: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:41:16.139408: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 402ms/step - loss: 0.5071 - rmse: 0.7121 - val_loss: 0.3769 - val_rmse: 0.6143 - learning_rate: 0.0010\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:42:09.137747: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:42:09.137874: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.4924 - rmse: 0.7017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:43:04.494266: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:43:04.494348: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 402ms/step - loss: 0.4988 - rmse: 0.7063 - val_loss: 0.4096 - val_rmse: 0.6403 - learning_rate: 0.0010\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:43:58.086218: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-10-05 23:43:58.086295: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:43:58.086325: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.4851 - rmse: 0.6963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:44:52.778114: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:44:52.778179: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 397ms/step - loss: 0.4840 - rmse: 0.6955 - val_loss: 0.4085 - val_rmse: 0.6395 - learning_rate: 0.0010\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:45:45.724849: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:45:45.724939: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.4594 - rmse: 0.6775"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:46:40.802172: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:46:40.802253: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 398ms/step - loss: 0.4610 - rmse: 0.6786 - val_loss: 0.4153 - val_rmse: 0.6447 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:47:33.589476: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:47:33.589545: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.4454 - rmse: 0.6670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:48:28.063929: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:48:28.064058: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 397ms/step - loss: 0.4493 - rmse: 0.6699 - val_loss: 0.4043 - val_rmse: 0.6361 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:49:21.148146: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:49:21.148239: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n"
     ]
    }
   ],
   "source": [
    "model_auto.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                   loss=masked_mse,\n",
    "                   metrics=[MaskedRMSE()])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_rmse\", mode=\"min\", patience=4, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_rmse\", mode=\"min\", factor=0.5, patience=2, min_lr=1e-5),\n",
    "]\n",
    "\n",
    "history = model_auto.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7c48b0f-20ad-48a9-9ce3-4943a76b4bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 202ms/step - loss: 0.3769 - rmse: 0.6144\n",
      "[0.3768567442893982, 0.6144348382949829]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 23:52:11.944856: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4817683161425880201\n",
      "2025-10-05 23:52:11.944943: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 10799239012569361700\n",
      "/home/anubh/miniconda3/envs/dl-env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    }
   ],
   "source": [
    "test_metrics = model_auto.evaluate(test_ds, verbose=1)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b94e9d-bb69-4e78-91eb-2db3904fd736",
   "metadata": {},
   "source": [
    "## MF-BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "98722d78-7580-4e41-9ce0-72a7dc709efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_THRESH = THRESH \n",
    "gt_by_user = defaultdict(set)\n",
    "for u, i, r in zip(test_df[\"user_idx\"].values,\n",
    "                   test_df[\"movie_idx\"].values,\n",
    "                   test_df[\"rating\"].values):\n",
    "    if r >= REL_THRESH:\n",
    "        gt_by_user[int(u)].add(int(i))\n",
    "\n",
    "# Warm-user eval cohort: users with TRAIN history and at least 1 GT item\n",
    "warm_users = set(np.unique(train_df[\"user_idx\"].values).tolist())\n",
    "users_eval = np.array([u for u in np.unique(test_df[\"user_idx\"].values)\n",
    "                       if (u in warm_users) and (len(gt_by_user.get(int(u), ())) > 0)],\n",
    "                      dtype=np.int32)\n",
    "\n",
    "d = 128  # embedding dimension \n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "user_factors = tf.Variable(tf.random.normal([n_users, d], stddev=0.05))\n",
    "item_factors = tf.Variable(tf.random.normal([n_items, d], stddev=0.05))\n",
    "item_bias    = tf.Variable(tf.zeros([n_items], tf.float32))  # optional\n",
    "\n",
    "def sample_triplets(batch_size):\n",
    "    u_batch = np.empty(batch_size, np.int32)\n",
    "    i_batch = np.empty(batch_size, np.int32)\n",
    "    j_batch = np.empty(batch_size, np.int32)\n",
    "\n",
    "    # sample users with positives\n",
    "    ub = users_with_pos[rng.integers(0, len(users_with_pos), size=batch_size)]\n",
    "    u_batch[:] = ub\n",
    "\n",
    "    # sample a positive per user\n",
    "    for k, u in enumerate(ub):\n",
    "        pos_list = list(positives_by_user[int(u)])\n",
    "        i_batch[k] = pos_list[rng.integers(0, len(pos_list))]\n",
    "\n",
    "    # sample negatives (resample on collision)\n",
    "    j_batch = rng.integers(0, n_items, size=batch_size, dtype=np.int32)\n",
    "    for k, u in enumerate(ub):\n",
    "        while j_batch[k] in positives_by_user[int(u)]:\n",
    "            j_batch[k] = int(rng.integers(0, n_items))\n",
    "    return u_batch, i_batch, j_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0905bc75-c2d1-4959-9051-5ebf75a3341e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(26744, 128) dtype=float32, numpy=\n",
       "array([[-0.00320732, -0.06844097,  0.12959965, ...,  0.02854785,\n",
       "        -0.01091599,  0.04180642],\n",
       "       [-0.06230679, -0.022381  , -0.02652861, ..., -0.02634893,\n",
       "         0.01627517,  0.01918394],\n",
       "       [ 0.01496974,  0.01557859, -0.02968986, ...,  0.06741958,\n",
       "        -0.05334706,  0.09160335],\n",
       "       ...,\n",
       "       [-0.02817411,  0.0003989 ,  0.00116769, ...,  0.01579854,\n",
       "         0.06870127, -0.02801405],\n",
       "       [-0.03164991,  0.04216761, -0.06880376, ...,  0.003628  ,\n",
       "        -0.05193505,  0.01366765],\n",
       "       [ 0.00552381, -0.06155177,  0.04973213, ..., -0.01202566,\n",
       "        -0.013162  , -0.02437686]], shape=(26744, 128), dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "55b52e1a-9d5a-4f91-a9af-f802b454b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-3)\n",
    "l2 = 1e-6\n",
    "clip_norm = 5.0\n",
    "\n",
    "@tf.function\n",
    "def train_step(u, i, j):\n",
    "    with tf.GradientTape() as tape:\n",
    "        U  = tf.gather(user_factors, u)    # [B, d]\n",
    "        Vi = tf.gather(item_factors, i)    # [B, d]\n",
    "        Vj = tf.gather(item_factors, j)    # [B, d]\n",
    "        bi = tf.gather(item_bias, i)       # [B]\n",
    "        bj = tf.gather(item_bias, j)       # [B]\n",
    "\n",
    "        s_pos = tf.reduce_sum(U * Vi, axis=1) + bi\n",
    "        s_neg = tf.reduce_sum(U * Vj, axis=1) + bj\n",
    "        x = s_pos - s_neg\n",
    "\n",
    "        bpr = - tf.reduce_mean(tf.math.log_sigmoid(x))   # pairwise ranking loss\n",
    "        reg = l2 * (tf.nn.l2_loss(U) + tf.nn.l2_loss(Vi) + tf.nn.l2_loss(Vj) +\n",
    "                    tf.nn.l2_loss(bi) + tf.nn.l2_loss(bj))\n",
    "        loss = bpr + reg\n",
    "\n",
    "    vars_ = [user_factors, item_factors, item_bias]\n",
    "    grads = tape.gradient(loss, vars_)\n",
    "    grads, _ = tf.clip_by_global_norm(grads, clip_norm)\n",
    "    opt.apply_gradients(zip(grads, vars_))\n",
    "    return loss\n",
    "\n",
    "def bpr_scores_batch(u_batch):\n",
    "    U = tf.gather(user_factors, u_batch)                         # [B, d]\n",
    "    scores = tf.matmul(U, item_factors, transpose_b=True) + item_bias  # [B, n_items]\n",
    "    return scores.numpy()\n",
    "\n",
    "def topk_batch(scores, K, batch_users):\n",
    "    # scores: [B, n_items]\n",
    "    scores = scores.copy()\n",
    "    for bi, u in enumerate(batch_users):\n",
    "        seen = seen_by_user.get(int(u), None)\n",
    "        if seen:\n",
    "            scores[bi, list(seen)] = -1e9\n",
    "    idx = np.argpartition(scores, -K, axis=1)[:, -K:]\n",
    "    row = np.arange(idx.shape[0])[:, None]\n",
    "    idx_sorted = idx[row, np.argsort(scores[row, idx], axis=1)[:, ::-1]]\n",
    "    return idx_sorted  # [B, K]\n",
    "\n",
    "def precision_at_k_batched(K=10, batch_users=1024):\n",
    "    precisions = []\n",
    "    for s in range(0, len(users_eval), batch_users):\n",
    "        ub = users_eval[s:s+batch_users]\n",
    "        scores = bpr_scores_batch(ub)\n",
    "        recs = topk_batch(scores, K, ub)\n",
    "        for bi, u in enumerate(ub):\n",
    "            gt = gt_by_user.get(int(u), None)\n",
    "            if not gt: continue\n",
    "            hits = len(set(recs[bi]) & gt)\n",
    "            precisions.append(hits / K)\n",
    "    return float(np.mean(precisions)) if precisions else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a6708e9-1109-4181-9173-111306462321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg loss=0.1477  Prec@10=0.0790\n",
      "Epoch 2: avg loss=0.0868  Prec@10=0.0836\n",
      "Epoch 3: avg loss=0.0838  Prec@10=0.0870\n",
      "Epoch 4: avg loss=0.0828  Prec@10=0.0893\n",
      "Epoch 5: avg loss=0.0823  Prec@10=0.0894\n",
      "Epoch 6: avg loss=0.0821  Prec@10=0.0916\n",
      "Epoch 7: avg loss=0.0819  Prec@10=0.0906\n",
      "Epoch 8: avg loss=0.0818  Prec@10=0.0933\n",
      "Epoch 9: avg loss=0.0818  Prec@10=0.0924\n",
      "Epoch 10: avg loss=0.0817  Prec@10=0.0910\n",
      "Epoch 11: avg loss=0.0816  Prec@10=0.0924\n",
      "Epoch 12: avg loss=0.0817  Prec@10=0.0923\n",
      "Epoch 13: avg loss=0.0816  Prec@10=0.0923\n",
      "Epoch 14: avg loss=0.0815  Prec@10=0.0938\n",
      "Epoch 15: avg loss=0.0816  Prec@10=0.0926\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 2000\n",
    "batch_size      = 8192\n",
    "epochs          = 15\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    losses = []\n",
    "    for _ in range(steps_per_epoch):\n",
    "        u, i, j = sample_triplets(batch_size)\n",
    "        loss = train_step(u, i, j)\n",
    "        losses.append(float(loss))\n",
    "    p10 = precision_at_k_batched(K=10, batch_users=1024) \n",
    "    print(f\"Epoch {epoch}: avg loss={np.mean(losses):.4f}  Prec@10={p10:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "465fffbb-519e-4023-b6f5-8b81c63654a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- MF+BPR scorer (uses trained embeddings) ----\n",
    "def bpr_scores_batch(u_batch):\n",
    "    U = tf.gather(user_factors, u_batch)                         # [B, d]\n",
    "    scores = tf.matmul(U, item_factors, transpose_b=True)        # [B, n_items]\n",
    "    scores = scores + item_bias                                  # broadcast add\n",
    "    return scores.numpy()\n",
    "\n",
    "# ---- AutoRec scorer (uses your trained AE and TRAIN CSR rows as input) ----\n",
    "# If you trained with global centering, you can add global_mean back. For ranking it doesn't change order.\n",
    "def autorec_scores_batch(u_batch, add_back_mean=0.0):\n",
    "    Xb = train_csr[u_batch].toarray().astype(np.float32)         # [B, n_items]\n",
    "    preds = model_auto(Xb, training=False).numpy()                # [B, n_items]\n",
    "    if add_back_mean:\n",
    "        preds = preds + float(add_back_mean)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def recall_at_k(users, K, scores_fn, batch_users=1024):\n",
    "    users = np.asarray(users, dtype=np.int32)\n",
    "    recalls = []\n",
    "    bad_seen_total = 0\n",
    "    for s in range(0, len(users), batch_users):\n",
    "        ub = users[s:s+batch_users]\n",
    "        scores = scores_fn(ub)                                    # [B, n_items]\n",
    "        n_cols = scores.shape[1]\n",
    "\n",
    "        # Safe masking with guard + lightweight diagnostics\n",
    "        for bi, u in enumerate(ub):\n",
    "            seen = seen_by_user.get(int(u), None)\n",
    "            if seen:\n",
    "                cols = np.fromiter(seen, dtype=np.int64)\n",
    "                bad = (cols < 0) | (cols >= n_cols)\n",
    "                bad_seen_total += int(bad.sum())\n",
    "                cols = cols[~bad]\n",
    "                if cols.size:\n",
    "                    scores[bi, cols] = -1e9\n",
    "\n",
    "        idx = np.argpartition(scores, -K, axis=1)[:, -K:]\n",
    "        row = np.arange(idx.shape[0])[:, None]\n",
    "        idx_sorted = idx[row, np.argsort(scores[row, idx], axis=1)[:, ::-1]]\n",
    "\n",
    "        for bi, u in enumerate(ub):\n",
    "            gt = gt_by_user.get(int(u), None)\n",
    "            if not gt:\n",
    "                continue\n",
    "            hits = len(set(idx_sorted[bi]) & gt)\n",
    "            recalls.append(hits / len(gt))\n",
    "\n",
    "    if bad_seen_total > 0:\n",
    "        print(f\"[warn] Ignored {bad_seen_total} out-of-range seen indices during masking.\")\n",
    "    return float(np.mean(recalls)) if recalls else 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6487e5c2-386e-4d2f-8883-6c654650e7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warn] Ignored 24 out-of-range seen indices during masking.\n",
      "Recall@10 (BPR): 0.1645596539634774\n",
      "Recall@10 (AutoRec): 6.800261421028686e-05\n"
     ]
    }
   ],
   "source": [
    "warm_users = set(np.unique(train_df[\"user_idx\"].values).tolist())\n",
    "\n",
    "users_eval = np.array([u for u in np.unique(test_df[\"user_idx\"].values)\n",
    "                       if (u in warm_users) and (len(gt_by_user.get(int(u), ())) > 0)],\n",
    "                      dtype=np.int32)\n",
    "\n",
    "recall10_bpr   = recall_at_k(users_eval, K=10, scores_fn=bpr_scores_batch)\n",
    "recall10_ae    = recall_at_k(users_eval, K=10, scores_fn=lambda ub: autorec_scores_batch(ub, add_back_mean=global_mean))\n",
    "print(\"Recall@10 (BPR):\", recall10_bpr)\n",
    "print(\"Recall@10 (AutoRec):\", recall10_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aee81479-7f89-4bb7-9331-298460921fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_user_idx(raw_user_id):\n",
    "    row = df.loc[df[\"userId\"].eq(raw_user_id), [\"user_idx\"]].drop_duplicates()\n",
    "    if row.empty:\n",
    "        return None\n",
    "    return int(row[\"user_idx\"].iloc[0])\n",
    "\n",
    "def recommend_top10_bpr(raw_user_id):\n",
    "    uidx = get_user_idx(raw_user_id)\n",
    "    if uidx is None:\n",
    "        return []  # cold-start; fall back to popularity\n",
    "    scores = bpr_scores_batch(np.array([uidx]))[0]               # [n_items]\n",
    "    seen = seen_by_user.get(uidx, None)\n",
    "    if seen:\n",
    "        scores[list(seen)] = -1e9\n",
    "    idx = np.argpartition(scores, -10)[-10:]\n",
    "    idx = idx[np.argsort(scores[idx])[::-1]]\n",
    "    return [(int(movieId_by_index[i]), str(title_by_index[i]), float(scores[i])) for i in idx]\n",
    "\n",
    "def recommend_top10_autorec(raw_user_id, add_back_mean=0.0):\n",
    "    uidx = get_user_idx(raw_user_id)\n",
    "    if uidx is None:\n",
    "        return []\n",
    "    scores = autorec_scores_batch(np.array([uidx]), add_back_mean=add_back_mean)[0]\n",
    "    seen = seen_by_user.get(uidx, None)\n",
    "    if seen:\n",
    "        scores[list(seen)] = -1e9\n",
    "    idx = np.argpartition(scores, -10)[-10:]\n",
    "    idx = idx[np.argsort(scores[idx])[::-1]]\n",
    "    return [(int(movieId_by_index[i]), str(title_by_index[i]), float(scores[i])) for i in idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6cd003fa-c81f-487f-a55e-ed862ddedc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top‑10 (BPR): [(912, 'Casablanca (1942)', 4.272552490234375), (1284, 'Big Sleep, The (1946)', 4.100092887878418), (1283, 'High Noon (1952)', 4.0522308349609375), (913, 'Maltese Falcon, The (1941)', 3.9904019832611084), (1304, 'Butch Cassidy and the Sundance Kid (1969)', 3.9713573455810547), (969, 'African Queen, The (1951)', 3.9665236473083496), (930, 'Notorious (1946)', 3.946599245071411), (904, 'Rear Window (1954)', 3.929795742034912), (951, 'His Girl Friday (1940)', 3.8872950077056885), (1953, 'French Connection, The (1971)', 3.85772705078125)]\n",
      "\n",
      "Top‑10 (AutoRec): [(88059, 'Bikini Summer (1991)', 5.306845664978027), (67361, 'Echelon Conspiracy (2009)', 5.292651176452637), (47028, \"Sione's Wedding (Samoan Wedding) (2006)\", 5.229885578155518), (104041, 'Arrival II (1998)', 5.193790435791016), (90114, 'I Dream Too Much (1935)', 5.171387672424316), (51277, '36th Chamber of Shaolin, The (Shao Lin san shi liu fang) (Master Killer) (1978)', 5.153675079345703), (58904, 'Chan Is Missing (1982)', 5.106273651123047), (4410, 'Something Wild (1986)', 5.094560146331787), (6259, 'My Friend Flicka (1943)', 5.091676235198975), (80214, 'Swan and the Wanderer, The (Kulkuri ja joutsen) (1999)', 5.040666580200195)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top‑10 (BPR):\", recommend_top10_bpr(raw_user_id=502))\n",
    "print(\"\\nTop‑10 (AutoRec):\", recommend_top10_autorec(raw_user_id=502, add_back_mean=global_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a437a-baa6-4251-81fc-4d562a4407fd",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f082c1-35bc-47df-944f-ec822eafbd32",
   "metadata": {},
   "source": [
    "In this project on the Movielens 20 Million dataset we first focused on the ratings and focused on RMSE based models, and then focused on models used for better retrievers. While all of them could be improved by using genre, tags, and more data, these models represents building blocks of modern recommendation systems.\n",
    "\n",
    "Multi-VAE and BPR based models beside others could be used in getting better top k recommendations while RMSE based models like NeuralMF and AutoRec would focus on the better score creation. And while we did obtain a good score in AutoRec, NeuralMF is also a valid good choice as its more robust in our testing. But for retrieving task MF-BPR outperformed both of them who were just recommending top k movies randomly. Nevertheless, all three models have their pros and cons and we could use a stack combining features of all of them, making a producing ready and scalable Recommendation System."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
